#!/bin/bash

echo "ðŸš€ Setting up Free Local AI with Ollama"
echo "======================================"

# Check if Ollama is installed
if command -v ollama &> /dev/null; then
    echo "âœ… Ollama is already installed"
else
    echo "ðŸ“¥ Installing Ollama..."
    curl -fsSL https://ollama.ai/install.sh | sh
fi

echo ""
echo "ðŸ”„ Starting Ollama service..."
ollama serve &
OLLAMA_PID=$!

# Wait a moment for service to start
sleep 5

echo ""
echo "ðŸ“¦ Downloading recommended models..."
echo "   â€¢ llama3.1:8b (8GB) - Best general model"
ollama pull llama3.1:8b

echo "   â€¢ llava:7b (4GB) - Vision model for image analysis"
ollama pull llava:7b

echo ""
echo "âœ… Setup complete!"
echo ""
echo "ðŸŽ¯ Usage:"
echo "   â€¢ Ollama is running in the background (PID: $OLLAMA_PID)"
echo "   â€¢ Use 'ollama list' to see installed models"
echo "   â€¢ Use 'ollama ps' to see running models"
echo "   â€¢ Kill service with: kill $OLLAMA_PID"
echo ""
echo "ðŸ”§ Your app can now use local AI instead of OpenAI!"
