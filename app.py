import streamlit as st
import os
from dotenv import load_dotenv
from PIL import Image
from agents.design_reviewer import DesignReviewAgent
from agents.document_loaders import document_loader_manager
from agents.vp_preferences import vp_preference_manager
from agents.local_reviewer import local_agent
from config.settings import settings

# Load environment variables
load_dotenv()

def display_review_results(review_result: dict, include_suggestions: bool, evaluation_mode: str = "Standard Design Review"):
    """Helper function to display review results consistently."""
    if 'error' in review_result:
        st.error(review_result['error'])
        if 'setup_instructions' in review_result:
            with st.expander("Setup Instructions"):
                setup = review_result['setup_instructions']
                if isinstance(setup, dict):
                    st.markdown("**Install Ollama:**")
                    st.code(setup.get('install', ''))
                    st.markdown("**Start Ollama:**")
                    st.code(setup.get('start', ''))
                    st.markdown("**Download Models:**")
                    if 'models' in setup:
                        for model_type, command in setup['models'].items():
                            st.code(command)
        return
    
    st.success("Analysis Complete!")
    
    # Source information
    if 'source' in review_result:
        source_info = f"ðŸ“Š Source: {review_result['source'].title()}"
        if review_result['source'] == 'local_ollama':
            source_info += f" (Model: {review_result.get('model', 'Unknown')})"
        elif 'file_key' in review_result:
            source_info += f" (File: {review_result['file_key'][:10]}...)"
        elif 'space_key' in review_result:
            source_info += f" (Space: {review_result['space_key']})"
        if 'pages_reviewed' in review_result:
            source_info += f" - {review_result['pages_reviewed']} pages"
        st.info(source_info)
    
    # Display based on evaluation mode
    if evaluation_mode == "Roku TV Design Review":
        display_roku_results(review_result)
    else:
        display_standard_results(review_result, include_suggestions)

def display_standard_results(review_result: dict, include_suggestions: bool):
    """Display standard design review results."""
    # Overall score
    if 'score' in review_result:
        st.metric("Design Score", f"{review_result['score']}/10")
    
    # Review content
    if 'review' in review_result:
        st.markdown("### Review")
        st.write(review_result['review'])
    
    # Suggestions
    if 'suggestions' in review_result and include_suggestions:
        st.markdown("### Suggestions for Improvement")
        for i, suggestion in enumerate(review_result['suggestions'], 1):
            st.write(f"{i}. {suggestion}")

def display_roku_results(review_result: dict):
    """Display Roku-specific evaluation results."""
    
    # Letter Grade (prominent display)
    if review_result.get('grade'):
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.metric("Roku Design Grade", review_result['grade'], help="Based on Roku TV design criteria")
    
    # Known Issues
    if review_result.get('known_issues'):
        st.markdown("### âš ï¸ Known Issues")
        for issue in review_result['known_issues']:
            st.write(f"â€¢ {issue}")
    
    # Priority Issues Table
    if review_result.get('priority_issues'):
        st.markdown("### ðŸ”¥ Priority Issues")
        st.caption("Ordered by priority (highest to lowest)")
        
        # Create a more structured table if we can parse the data
        issues_text = "\n".join(review_result['priority_issues'])
        st.write(issues_text)
    
    # Purpose and Value Questions
    if review_result.get('questions'):
        st.markdown("### â“ Purpose & Value Questions")
        for question in review_result['questions']:
            st.write(f"â€¢ {question}")
    
    # Critical User Journey Impact
    if review_result.get('journey_impact'):
        st.markdown("### ðŸ›¤ï¸ Critical User Journey Impact")
        impact_text = str(review_result['journey_impact'])
        st.write(impact_text)
    
    # Improvement Suggestions
    if review_result.get('suggestions'):
        st.markdown("### ðŸ’¡ Scope Expansion Suggestions")
        for suggestion in review_result['suggestions']:
            st.write(f"â€¢ {suggestion}")
    
    # Full Evaluation (collapsible)
    if review_result.get('full_evaluation'):
        with st.expander("ðŸ“„ Full Detailed Evaluation"):
            st.markdown(review_result['full_evaluation'])

def main():
    st.set_page_config(
        page_title="Margo - AI Design Review",
        page_icon="ðŸŽ¨",
        layout="wide"
    )
    
    st.title("ðŸŽ¨ Margo - AI Design Review Assistant")
    st.markdown("Upload your design files and get AI-powered feedback!")
    
    # Check AI provider configuration
    use_free_ai = st.sidebar.checkbox(
        "ðŸ†“ Use Free Cloud AI",
        help="Use free cloud AI providers (Groq, Hugging Face) instead of OpenAI. No API key required for some providers!"
    )
    
    if not use_free_ai and not os.getenv("OPENAI_API_KEY"):
        st.warning("âš ï¸ OpenAI API key not configured. Enable 'Use Free Cloud AI' in the sidebar for free alternatives.")
        
        with st.expander("ðŸ”§ Setup Options"):
            st.markdown("""
            **Option 1: OpenAI (Recommended for best quality)**
            - Get $5 free credits: https://platform.openai.com/
            - Add your API key to the .env file
            
            **Option 2: Free Cloud AI (Groq, Hugging Face, etc.)**
            - âœ… Many completely free options
            - âœ… Fast inference (especially Groq)
            - âœ… No local installation needed
            - Check 'Use Free Cloud AI' in sidebar
            """)
        
        if not use_free_ai:
            st.stop()
    
    # Initialize the appropriate agent
    if use_free_ai:
        from agents.cloud_reviewer import cloud_agent
        if cloud_agent.is_available():
            st.sidebar.success("ðŸ†“ Using Free Cloud AI")
            st.sidebar.info(f"Provider: {cloud_agent.provider}")
        else:
            st.sidebar.error("No free cloud AI providers configured.")
            with st.sidebar.expander("Setup Free Cloud AI"):
                setup_info = cloud_agent.get_setup_instructions()
                st.markdown("**Recommended: Groq (Free & Fast)**")
                st.markdown("1. Go to https://console.groq.com/")
                st.markdown("2. Sign up and get your API key")
                st.markdown("3. Add `GROQ_API_KEY=your_key` to your .env file")
                st.markdown("4. Restart the app")
        agent = None  # We'll use cloud_agent directly
    else:
        st.sidebar.success("ðŸ”‘ Using OpenAI API")
        agent = DesignReviewAgent()
    
    # Sidebar for configuration
    with st.sidebar:
        st.header("Review Settings")
        
        evaluation_mode = st.selectbox(
            "Evaluation Mode",
            ["Standard Design Review", "Roku TV Design Review"],
            help="Choose between general design review or Roku-specific TV interface evaluation"
        )
        
        if evaluation_mode == "Standard Design Review":
            review_type = st.selectbox(
                "Review Type",
                ["General Design", "UI/UX", "Accessibility", "Brand Consistency"]
            )
            
            detail_level = st.slider(
                "Detail Level",
                min_value=1,
                max_value=5,
                value=3,
                help="1 = Brief overview, 5 = Detailed analysis"
            )
            
            include_suggestions = st.checkbox(
                "Include Improvement Suggestions",
                value=True
            )
            
            # Standard review variables
            roku_focus_areas = None
            roku_context = ""
            include_grading = False
            
        else:  # Roku TV Design Review
            st.markdown("**Roku TV Design Evaluation**")
            st.caption("Using your VP's comprehensive evaluation criteria")
            
            with st.expander("â„¹ï¸ About Roku TV Design Review"):
                st.markdown("""
                This evaluation mode uses the **exact criteria from your VP** for Roku TV interface design review:
                
                **Key Principles Evaluated:**
                - ðŸŽ¯ **Easy**: Minimal effort to achieve user goals, clear primary purpose
                - âš¡ **Just Works**: Snappy, reliable, error-free experience  
                - ðŸ‘€ **Looks Simple**: Clear visual communication, minimal clutter
                - ðŸ¤ **Trustworthy**: Meets expectations, straightforward communication
                - ðŸ˜Š **Delightful**: Unexpected smiles and helpful features
                - ðŸŽ¯ **Outcome-Focused**: Meets user needs while supporting business goals
                
                **What You Get:**
                - Prioritized issues table with actionable recommendations
                - Critical user journey impact analysis
                - Letter grade (A-F) based on Roku standards
                - TV remote control navigation compliance check
                - Accessibility and localization considerations
                
                **Solves the VP's Problem:** This system can actually *see* the images embedded in Confluence pages and Figma files, unlike ai.roku.com!
                """)
            
            roku_context = st.text_area(
                "Design Context",
                placeholder="e.g., UXDR Lite: Browse: Promo offers in BoB",
                help="Describe the specific feature or page being evaluated"
            )
            
            focus_areas_options = [
                "usability", "learnability", "information architecture", 
                "visual design", "accessibility", "localization", 
                "layout", "emotional impact", "navigation", "remote control usage"
            ]
            
            roku_focus_areas = st.multiselect(
                "Focus Areas (Optional)",
                focus_areas_options,
                help="Select specific areas to focus on, or leave empty for comprehensive review"
            )
            
            include_grading = st.checkbox(
                "Include Letter Grade",
                value=True,
                help="Assign A-F letter grade based on Roku criteria"
            )
            
            # Set standard review defaults for compatibility
            review_type = "Roku TV Design"
            detail_level = 5
            include_suggestions = True
    
    
    # Main content area - simplified structure
    st.markdown("---")
    
    # Simple input selection
    input_method = st.radio(
        "How would you like to provide your design?",
        ["ðŸ“ Upload File", "ðŸŽ¨ Figma URL", "ðŸ“š Confluence Page"],
        horizontal=True
    )
    
    st.markdown("---")
    
    # Single content area based on selection
    if input_method == "ðŸ“ Upload File":
        show_file_upload_interface(use_free_ai, agent, evaluation_mode, review_type, detail_level, include_suggestions, roku_context, roku_focus_areas, include_grading)
    
    elif input_method == "ðŸŽ¨ Figma URL":
        show_figma_interface(use_free_ai, agent, evaluation_mode, review_type, detail_level, include_suggestions, roku_context, roku_focus_areas, include_grading)
    
    elif input_method == "ðŸ“š Confluence Page":
        show_confluence_interface(use_free_ai, agent, evaluation_mode, review_type, detail_level, include_suggestions, roku_context, roku_focus_areas, include_grading)

def show_file_upload_interface(use_free_ai, agent, evaluation_mode, review_type, detail_level, include_suggestions, roku_context, roku_focus_areas, include_grading):
    """Simplified file upload interface."""
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("Upload Your Design")
        
        uploaded_file = st.file_uploader(
            "Choose a design file",
            type=['png', 'jpg', 'jpeg', 'pdf'],
            help="Upload images or PDF files containing your designs"
        )
        
        if uploaded_file is not None:
            if uploaded_file.type.startswith('image'):
                image = Image.open(uploaded_file)
                st.image(image, caption="Uploaded Design", use_column_width=True)
            else:
                st.success(f"PDF uploaded: {uploaded_file.name}")
    
    with col2:
        st.subheader("Analysis Results")
        
        if uploaded_file is not None:
            if st.button("ðŸ” Analyze Design", type="primary", key="file_analyze"):
                with st.spinner("Analyzing design..."):
                    try:
                        if use_free_ai:
                            # Use cloud AI
                            from agents.cloud_reviewer import cloud_agent
                            if cloud_agent.is_available():
                                if uploaded_file.type.startswith('image'):
                                    # For images with cloud AI, we need a text description
                                    review_result = {
                                        'error': 'Image analysis requires OpenAI. Please provide a text description of the image instead.',
                                        'suggestion': 'Switch to "ðŸ“ Text Description" and describe your image in detail.'
                                    }
                                else:
                                    # For PDFs with cloud AI, extract text content
                                    review_result = {
                                        'error': 'PDF analysis requires OpenAI. Please extract the text content and use "ðŸ“ Text Description" instead.',
                                        'suggestion': 'Copy the text from your PDF and use the text description option.'
                                    }
                            else:
                                review_result = {
                                    'error': 'No cloud AI provider configured.',
                                    'setup_instructions': cloud_agent.get_setup_instructions()
                                }
                        else:
                            # Use OpenAI agent
                            if evaluation_mode == "Roku TV Design Review":
                                # Use Roku-specific evaluation
                                review_result = agent.review_roku_design(
                                    uploaded_file,
                                    input_type="file",
                                    design_context=roku_context,
                                    focus_areas=roku_focus_areas if roku_focus_areas else None,
                                    include_grading=include_grading
                                )
                            else:
                                # Use standard evaluation
                                review_result = agent.review_design(
                                    uploaded_file,
                                    review_type=review_type,
                                    detail_level=detail_level,
                                    include_suggestions=include_suggestions
                                )
                        
                        # Display results
                        display_review_results(review_result, include_suggestions, evaluation_mode)
                        
                    except Exception as e:
                        st.error(f"Error analyzing design: {str(e)}")
        else:
            st.info("Upload a design file to get started!")


def show_figma_interface(use_free_ai, agent, evaluation_mode, review_type, detail_level, include_suggestions, roku_context, roku_focus_areas, include_grading):
    """Simplified Figma interface."""
    if not settings.is_figma_configured():
        st.warning("âš ï¸ Figma integration requires configuration. Add your FIGMA_ACCESS_TOKEN to the .env file.")
        return
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("Figma File")
        
        figma_input = st.text_input(
            "Figma URL or File Key",
            placeholder="https://www.figma.com/file/abc123/Design-File",
            help="Paste the full Figma URL or just the file key"
        )
        
        node_ids_input = st.text_input(
            "Specific Nodes (Optional)",
            placeholder="123:45, 456:78",
            help="Comma-separated node IDs to analyze specific components"
        )
        
        if figma_input:
            # Extract file key
            if "figma.com" in figma_input:
                file_key = document_loader_manager.extract_figma_file_key(figma_input)
            else:
                file_key = figma_input
            
            st.info(f"File Key: {file_key}")
    
    with col2:
        st.subheader("Analysis Results")
        
        if figma_input:
            if st.button("ðŸ” Analyze Figma Design", type="primary", key="figma_analyze"):
                with st.spinner("Loading and analyzing Figma design..."):
                    try:
                        node_ids = [nid.strip() for nid in node_ids_input.split(',') if nid.strip()] if node_ids_input else None
                        
                        if use_free_ai:
                            st.warning("Cloud AI doesn't support Figma integration yet. Please use OpenAI or export images from Figma.")
                            return
                        
                        if evaluation_mode == "Roku TV Design Review":
                            review_result = agent.review_roku_design(
                                file_key,
                                input_type="figma",
                                design_context=roku_context,
                                focus_areas=roku_focus_areas if roku_focus_areas else None,
                                include_grading=include_grading,
                                node_ids=node_ids
                            )
                        else:
                            review_result = agent.review_figma_file(
                                file_key,
                                review_type=review_type,
                                detail_level=detail_level,
                                include_suggestions=include_suggestions,
                                node_ids=node_ids
                            )
                        
                        display_review_results(review_result, include_suggestions, evaluation_mode)
                        
                    except Exception as e:
                        st.error(f"Error analyzing Figma file: {str(e)}")
        else:
            st.info("Enter a Figma URL or file key to get started!")


def show_confluence_interface(use_free_ai, agent, evaluation_mode, review_type, detail_level, include_suggestions, roku_context, roku_focus_areas, include_grading):
    """Simplified Confluence interface."""
    if not settings.is_confluence_configured():
        st.warning("âš ï¸ Confluence integration requires configuration.")
        with st.expander("Setup Instructions"):
            st.code("""CONFLUENCE_URL=https://your-domain.atlassian.net
CONFLUENCE_USERNAME=your_email@domain.com
CONFLUENCE_API_KEY=your_api_key_here""")
        return
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("Confluence Page")
        
        space_key = st.text_input(
            "Space Key",
            placeholder="e.g., DESIGN, PROJ",
            help="The key of the Confluence space to analyze"
        )
        
        page_ids_input = st.text_area(
            "Page IDs (Optional)",
            placeholder="Enter specific page IDs, one per line",
            help="Leave empty to analyze all pages in the space"
        )
        
        page_ids = [pid.strip() for pid in page_ids_input.split('\n') if pid.strip()] if page_ids_input else None
        
        if space_key and not page_ids:
            st.info(f"Will analyze all pages in space: {space_key}")
        elif space_key and page_ids:
            st.info(f"Will analyze {len(page_ids)} specific pages in space: {space_key}")
    
    with col2:
        st.subheader("Analysis Results")
        
        if space_key:
            if st.button("ðŸ” Analyze Confluence Pages", type="primary", key="confluence_analyze"):
                with st.spinner("Loading and analyzing Confluence pages..."):
                    try:
                        if use_free_ai:
                            st.warning("Cloud AI doesn't support Confluence integration yet. Please use OpenAI or copy content manually.")
                            return
                        
                        if evaluation_mode == "Roku TV Design Review":
                            review_result = agent.review_roku_design(
                                space_key,
                                input_type="confluence",
                                design_context=roku_context,
                                focus_areas=roku_focus_areas if roku_focus_areas else None,
                                include_grading=include_grading,
                                page_ids=page_ids
                            )
                        else:
                            review_result = agent.review_confluence_pages(
                                space_key,
                                page_ids=page_ids,
                                review_type=review_type,
                                detail_level=detail_level,
                                include_suggestions=include_suggestions
                            )
                        
                        display_review_results(review_result, include_suggestions, evaluation_mode)
                        
                    except Exception as e:
                        st.error(f"Error analyzing Confluence pages: {str(e)}")
        else:
            st.info("Enter a Confluence space key to get started!")
    
    # VP Preferences & Learning Section
    st.markdown("---")
    st.header("âš™ï¸ VP Preferences & Learning")
    st.caption("Customize evaluation criteria and track learning over time")
    
    # Sub-tabs for different preference areas
    pref_tab1, pref_tab2, pref_tab3, pref_tab4 = st.tabs([
        "ðŸ“‹ Custom Rules", 
        "ðŸ‘¤ VP Profile", 
        "ðŸ“Š Learning Insights", 
        "ðŸ’¬ Feedback"
    ])
    
    with pref_tab1:
            st.subheader("Custom Design Rules")
            st.write("Add your own design requirements that will be included in all evaluations.")
            
            # Add new custom rule form
            with st.expander("âž• Add New Custom Rule"):
                with st.form("add_custom_rule"):
                    col1, col2 = st.columns([2, 1])
                    
                    with col1:
                        rule_title = st.text_input("Rule Title", placeholder="e.g., 'Focus indicators must be 4px thick'")
                        rule_description = st.text_area("Description", placeholder="Detailed description of the requirement...")
                        rule_rationale = st.text_area("Rationale", placeholder="Why is this rule important? What problem does it solve?")
                    
                    with col2:
                        rule_priority = st.slider("Priority", 1, 5, 3, help="5 = Critical, 1 = Nice to have")
                        rule_category = st.selectbox("Category", [
                            "navigation", "visual design", "accessibility", 
                            "performance", "usability", "content", "branding"
                        ])
                    
                    rule_examples = st.text_area("Examples (one per line)", placeholder="Good example 1\nGood example 2")
                    rule_exceptions = st.text_area("Exceptions (one per line)", placeholder="Exception case 1\nException case 2")
                    
                    if st.form_submit_button("Add Custom Rule", type="primary"):
                        if rule_title and rule_description:
                            examples = [ex.strip() for ex in rule_examples.split('\n') if ex.strip()]
                            exceptions = [ex.strip() for ex in rule_exceptions.split('\n') if ex.strip()]
                            
                            rule_id = agent.add_custom_requirement(
                                title=rule_title,
                                description=rule_description,
                                rationale=rule_rationale,
                                priority=rule_priority,
                                category=rule_category,
                                examples=examples,
                                exceptions=exceptions
                            )
                            st.success(f"Custom rule added! ID: {rule_id}")
                            st.rerun()
                        else:
                            st.error("Please provide at least a title and description.")
            
            # Display existing custom rules
            st.subheader("Existing Custom Rules")
            custom_rules = vp_preference_manager.custom_rules
            
            if custom_rules:
                for rule in custom_rules:
                    with st.expander(f"ðŸ”§ {rule.title} (Priority {rule.priority})"):
                        st.write(f"**Category:** {rule.category}")
                        st.write(f"**Description:** {rule.description}")
                        if rule.rationale:
                            st.write(f"**Rationale:** {rule.rationale}")
                        if rule.examples:
                            st.write(f"**Examples:** {', '.join(rule.examples)}")
                        if rule.exceptions:
                            st.write(f"**Exceptions:** {', '.join(rule.exceptions)}")
                        st.caption(f"Created: {rule.created_date} | Modified: {rule.last_modified}")
            else:
                st.info("No custom rules yet. Add your first rule above!")
        
    with pref_tab2:
            st.subheader("VP Profile Settings")
            st.write("Configure your evaluation style and preferences.")
            
            # Get current profile
            current_profile = vp_preference_manager.vp_profile
            
            with st.form("vp_profile"):
                col1, col2 = st.columns(2)
                
                with col1:
                    vp_name = st.text_input("Name", value=current_profile.name if current_profile else "")
                    vp_role = st.text_input("Role", value=current_profile.role if current_profile else "")
                    
                    communication_style = st.selectbox(
                        "Communication Style",
                        ["detailed", "concise", "visual", "bullet_points"],
                        index=["detailed", "concise", "visual", "bullet_points"].index(
                            current_profile.communication_style if current_profile else "detailed"
                        )
                    )
                
                with col2:
                    focus_areas = st.multiselect(
                        "Primary Focus Areas",
                        ["usability", "accessibility", "visual design", "navigation", "performance", "content", "branding"],
                        default=current_profile.focus_areas if current_profile else []
                    )
                    
                    strict_areas = st.multiselect(
                        "Areas where you're particularly strict",
                        ["accessibility", "navigation", "visual hierarchy", "performance", "content clarity"],
                        default=current_profile.strict_areas if current_profile else []
                    )
                
                if st.form_submit_button("Update Profile", type="primary"):
                    vp_preference_manager.update_vp_profile(
                        name=vp_name,
                        role=vp_role,
                        focus_areas=focus_areas,
                        strict_areas=strict_areas,
                        communication_style=communication_style
                    )
                    st.success("VP Profile updated!")
                    st.rerun()
        
    with pref_tab3:
            st.subheader("Learning Insights")
            st.write("See what the system has learned from your feedback over time.")
            
            # Get learning insights
            if agent is not None:
                insights = agent.get_learning_summary()
            else:
                # Local AI doesn't have learning insights yet
                insights = {"total_evaluations": 0}
            
            if insights.get("total_evaluations", 0) > 0:
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("Total Evaluations", insights["total_evaluations"])
                
                with col2:
                    st.metric("Average Rating", f"{insights.get('average_vp_rating', 0):.1f}/5")
                
                with col3:
                    if insights.get("grade_distribution"):
                        most_common_grade = max(insights["grade_distribution"].items(), key=lambda x: x[1])[0]
                        st.metric("Most Common Grade", most_common_grade)
                
                # Most common issues
                if insights.get("most_common_issues"):
                    st.subheader("Most Frequently Found Issues")
                    for issue_type, count in insights["most_common_issues"]:
                        st.write(f"â€¢ **{issue_type}**: {count} times")
                
                # Recent feedback
                if insights.get("recent_feedback"):
                    st.subheader("Recent Feedback Themes")
                    for feedback in insights["recent_feedback"]:
                        st.write(f"â€¢ {feedback}")
                
                # Grade distribution chart
                if insights.get("grade_distribution"):
                    st.subheader("Grade Distribution")
                    grades = list(insights["grade_distribution"].keys())
                    counts = list(insights["grade_distribution"].values())
                    
                    import plotly.express as px
                    import pandas as pd
                    
                    df = pd.DataFrame({"Grade": grades, "Count": counts})
                    fig = px.bar(df, x="Grade", y="Count", title="Evaluation Grade Distribution")
                    st.plotly_chart(fig, use_container_width=True)
            
            else:
                st.info("No evaluation history yet. Start evaluating designs to see learning insights!")
        
    with pref_tab4:
            st.subheader("Provide Feedback on Evaluations")
            st.write("Rate the quality of recent evaluations to help the system learn your preferences.")
            
            # Show recent evaluations for feedback
            recent_evaluations = vp_preference_manager.evaluation_memory[-5:]  # Last 5
            
            if recent_evaluations:
                for eval_mem in reversed(recent_evaluations):  # Most recent first
                    with st.expander(f"ðŸ“‹ {eval_mem.design_id} - {eval_mem.context[:50]}..."):
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            st.write(f"**Date:** {eval_mem.evaluation_date}")
                            st.write(f"**Type:** {eval_mem.input_type}")
                            st.write(f"**Context:** {eval_mem.context}")
                            st.write(f"**Grade Given:** {eval_mem.grade_assigned}")
                            
                            if eval_mem.vp_feedback:
                                st.write(f"**Your Previous Feedback:** {eval_mem.vp_feedback}")
                                st.write(f"**Your Rating:** {eval_mem.vp_rating}/5")
                            else:
                                st.info("No feedback provided yet")
                        
                        with col2:
                            if not eval_mem.vp_feedback:
                                with st.form(f"feedback_{eval_mem.design_id}"):
                                    vp_rating = st.slider("Rate this evaluation", 1, 5, 3, 
                                                        help="1=Poor, 5=Excellent", 
                                                        key=f"rating_{eval_mem.design_id}")
                                    vp_feedback = st.text_area("Feedback", 
                                                              placeholder="What was good/bad about this evaluation?",
                                                              key=f"feedback_text_{eval_mem.design_id}")
                                    
                                    if st.form_submit_button("Submit Feedback"):
                                        if agent.provide_evaluation_feedback(eval_mem.design_id, vp_feedback, vp_rating):
                                            st.success("Feedback recorded!")
                                            st.rerun()
                                        else:
                                            st.error("Failed to record feedback")
            else:
                st.info("No evaluations to provide feedback on yet.")
    
    # Chat interface
    st.header("ðŸ’¬ Chat with Design Agent")
    
    # Initialize chat history
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # Display chat messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # Chat input
    if prompt := st.chat_input("Ask questions about your design..."):
        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Get agent response
        with st.chat_message("assistant"):
            with st.spinner("Thinking..."):
                response = agent.chat(prompt)
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == "__main__":
    main()
